feedback: true
device: cuda
data_dir: /home/geopar/projects/mm/data/cmumosei
results_dir: /home/geopar/projects/mm/results/feedback_bi_3way_uni
binary: false
train: true
test: true
overfit_batch: false
debug: false
remove_pauses: true

normalize_audio: true
normalize_visual: true

modalities:
    - text
    - glove
    - audio
    - visual

audio:
    instance_norm: false
    model:
        input_size: 74
        hidden_size: 300
        layers: 1
        dropout: !!float 0.1
        bidirectional: false
        rnn_type: lstm
        attention: true
        return_hidden: false
        batchnorm: false

visual:
    instance_norm: false
    model:
        input_size: 35
        hidden_size: 300
        layers: 1
        dropout: !!float 0.1
        bidirectional: false
        rnn_type: lstm
        attention: true
        return_hidden: false
        batchnorm: false

text:
    model:
        input_size: 300
        hidden_size: 300
        layers: 1
        dropout: !!float 0.1
        bidirectional: false
        rnn_type: lstm
        attention: true
        return_hidden: false

fuse:
    method: cat
    modality_weights: false
    projection_size: 300
    prefuse: false
    use_mask: false

common:
    dropout: !!float 0.1
    bidirectional: false
    rnn_type: lstm

experiment:
    name: mosei-binary-audio-text-visual
    description: MOSEI binary task

embeddings:
    path: /data/embeddings/en/glove.840B.300d.txt
    dim: 300
    finetune: false
    dropout: !!float 0

dataloaders:
    batch_size: 64
    num_workers: 1
    pin_memory: false

optimizer:
    name: Adam
    learning_rate: !!float 1e-3

trainer:
    patience: 20
    max_epochs: 100
    retain_graph: true
    load_model: mosei-binary-audio-text-visual_checkpoint.best.pth
    checkpoint_dir: /home/geopar/projects/mm/checkpoints-feedback-uni
