feedback: true
device: cuda
data_dir: ./data/cmumosei
results_dir: /home/egeorgiou/experimental/mm/slp/results/monomodal_3way
binary: false
train: true
test: true
overfit_batch: false
debug: false
remove_pauses: true

modalities:
    - text
    - glove
    - audio
    - visual

audio:
    instance_norm: false
    model:
        input_size: 74
        hidden_size: 300
        layers: 1
        dropout: !!float 0.2
        bidirectional: true
        rnn_type: lstm
        attention: true
        return_hidden: false
        batchnorm: false

visual:
    instance_norm: false
    model:
        input_size: 35
        hidden_size: 300
        layers: 1
        dropout: !!float 0.2
        bidirectional: true
        rnn_type: lstm
        attention: true
        return_hidden: false
        batchnorm: false

text:
    model:
        input_size: 300
        hidden_size: 300
        layers: 1
        dropout: !!float 0.2
        bidirectional: true
        rnn_type: lstm
        attention: true
        return_hidden: false

fuse:
    method: cat
    modality_weights: false
    projection_size: 300
    prefuse: false
    use_mask: false

common:
    dropout: !!float 0.2
    bidirectional: true
    rnn_type: lstm

experiment:
    name: mosei-monomodal
    description: MOSEI binary task

embeddings:
    path: /data/embeddings/en/glove.840B.300d.txt
    dim: 300
    finetune: false
    dropout: !!float 0

dataloaders:
    batch_size: 64
    num_workers: 1
    pin_memory: false

optimizer:
    audio:
        name: Adam
        learning_rate: !!float 1e-3
    text:
        name: Adam
        learning_rate: !!float 1e-3
    visual:
        name: Adam
        learning_rate: !!float 1e-3

trainer:
    patience: 20
    max_epochs: 100
    retain_graph: true
    load_audio_model: mosei-audio_checkpoint.best.pth
    load_text_model: mosei-text_checkpoint.best.pth
    load_visual_model: mosei-visual_checkpoint.best.pth
    checkpoint_dir: /home/egeorgiou/experimental/mm/slp/checkpoints-mosei-monomodal
